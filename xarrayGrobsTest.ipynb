{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an xarray Dataset of ground observations\n",
    "- Addressing issues Nic and I have encountered while trying to create xarray.Datasets of ground observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Import statements\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "from netCDF4 import num2date, date2num\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# OS interaction\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Directory Lists\n",
    "dirSIO = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/data/GroundObs/YOS.SIO.Obs'\n",
    "dirOut = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/data/GroundObs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Site: bee\n",
      "Processed Site: dan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karllapo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:45: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).mean()\n",
      "/Users/karllapo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:46: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).mean()\n",
      "/Users/karllapo/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:47: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).mean()\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "## Ground Obs: SIO\n",
    "# Empty lists and dictionary literals\n",
    "stations = []\n",
    "lat = []\n",
    "lon = []\n",
    "elev = []\n",
    "network = []\n",
    "grobs = {}\n",
    "count = 0\n",
    "\n",
    "# time zone variables\n",
    "tz_pst = pytz.timezone('US/Pacific')\n",
    "\n",
    "#########################\n",
    "##### READ SIO DATA #####\n",
    "#########################\n",
    "os.chdir(dirSIO)\n",
    "content = os.listdir(os.getcwd())\n",
    "num_files = len([name for name in os.listdir('.') if os.path.isfile(name)])\n",
    "na_value = ['   NaN']\n",
    "\n",
    "# Read supporting station information\n",
    "os.chdir(dirOut)\n",
    "stdat = pd.read_csv('All_StationSummary.v2.csv',sep= ',', \\\n",
    "                index_col=0,na_values=[-9999,'NaN']) # Read the supporting information\n",
    "stdat = stdat.groupby('Network').get_group('CDWR')\n",
    "\n",
    "for files in content:\n",
    "    # Only read QC formatted files\n",
    "    if files[-10:] == 'Rad.QC.txt':\n",
    "        count = count + 1\n",
    "        if count > 2:\n",
    "            break\n",
    "        \n",
    "        # What file are we reading?\n",
    "        sitename = files.split('.')[0]\n",
    "        stations.append(sitename)\n",
    "\n",
    "        # Read SW data, asign to PST, and get SW that passes QC\n",
    "        grobs_yos = pd.read_csv(files,sep= '\\t', parse_dates=True, index_col=0, na_values=na_value)\n",
    "        grobs_yos.index = grobs_yos.index#.tz_localize(pytz.utc).tz_convert(tz_pst)\n",
    "        grobs_yos['SWdwn_QC'] = grobs_yos['SWdwn_Wm^-2'].where(grobs_yos['QCFlag'] == 0)\n",
    "\n",
    "        # New data frame w/ daily means\n",
    "        grobs_yos_daily = grobs_yos['SWdwn_Wm^-2'].resample('D', how='mean').to_frame(name='SWdwn_D')\n",
    "        grobs_yos_daily['SWdwn_D_QC'] = grobs_yos['SWdwn_QC'].resample('D', how='mean')\n",
    "        grobs_yos_daily['SWdwn_D_proc'] = grobs_yos['SWdwn_proc'].resample('D', how='mean')\n",
    "\n",
    "        # List containing DataFrames with daily, processed only\n",
    "        grobs[sitename] = pd.DataFrame(grobs_yos_daily['SWdwn_D_proc'])\n",
    "        grobs[sitename].columns = ['SWdwn']\n",
    "        grobs[sitename].index = grobs_yos_daily.index\n",
    "\n",
    "        # Fill in elevation/lat/lon/network\n",
    "        elev.append(stdat.loc[sitename]['elevation (m)'])\n",
    "        lat.append(stdat.loc[sitename]['lat'])\n",
    "        lon.append(stdat.loc[sitename]['lon'])\n",
    "        network.append('CDWR')\n",
    "\n",
    "        print((\"Processed Site: \"+sitename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:   (datetime: 2972, station: 2)\n",
      "Coordinates:\n",
      "  * datetime  (datetime) datetime64[ns] 2004-08-27 2004-08-28 2004-08-29 ...\n",
      "  * station   (station) int64 0 1\n",
      "Data variables:\n",
      "    SWdwn     (station, datetime) float64 808.2 264.9 239.8 254.9 284.9 ...\n"
     ]
    }
   ],
   "source": [
    "# convert each site from a pandas Dataframe to an xarray Dataset\n",
    "grobsXR = {}\n",
    "for site in grobs:\n",
    "    grobsXR[site] = xr.Dataset.from_dataframe(grobs[site])\n",
    "    \n",
    "# align each Dataset - this approach won't work for list comprehension (align does not expect lists.\n",
    "[grobsXR['dan'],grobsXR['bee']] = xr.align(grobsXR['dan'],grobsXR['bee'],join='outer')\n",
    "grobsXR = xr.concat([grobsXR['dan'],grobsXR['bee']],dim='station')\n",
    "\n",
    "print(grobsXR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (station: 2, time: 2972)\n",
      "Coordinates:\n",
      "  * station  (station) object 'bee' 'dan'\n",
      "  * time     (time) datetime64[ns] 2004-08-27 2004-08-28 2004-08-29 ...\n",
      "    lat      (station) float64 37.53 37.9\n",
      "    lon      (station) float64 118.3 119.3\n",
      "    elev     (station) float64 2.768e+03 2.987e+03\n",
      "    network  (station) |S4 'CDWR' 'CDWR'\n",
      "Data variables:\n",
      "    SWdwn    (station, time) float64 nan nan nan nan nan nan nan nan nan nan ...\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "##### Combine data using pandas Dataframes -- this approach is robust for ragged station data\n",
    "# Concatenate \n",
    "grobs_daily = pd.concat(grobs,axis=0,keys=stations)\n",
    "grobs_daily = pd.DataFrame(grobs_daily)\n",
    "\n",
    "# Convert to xray\n",
    "ds = xr.Dataset.from_dataframe(grobs_daily)\n",
    "ds = ds.rename({'level_0':'station','datetime':'time'})\n",
    "\n",
    "# Fill in descriptive variables\n",
    "ds.coords['lat'] = ('station',lat)\n",
    "ds.coords['lon'] = ('station',lon)\n",
    "ds.coords['elev'] = ('station',elev)\n",
    "ds.coords['network'] = ('station',network)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
