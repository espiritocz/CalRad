{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Networks for import -- CIMIS and SIO/CDWR\n",
      "flag_xray_proc = 0\n",
      "\n",
      "## Import statements\n",
      "import numpy as np\n",
      "import xray\n",
      "import pandas as pd\n",
      "from netCDF4 import Dataset\n",
      "from netCDF4 import num2date, date2num\n",
      "from datetime import datetime, timedelta\n",
      "import pytz\n",
      "\n",
      "# OS interaction\n",
      "import sys\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Directory Lists\n",
      "# General directories\n",
      "dir_data_out = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/data/GroundObs'\n",
      "dir_print = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/Graphics'\n",
      "\n",
      "# Individual data directories\n",
      "dir_cv_cimis_ucipm = '/Users/karllapo/gdrive/GroundObs/CA_CentralValley.UCDavis/RAW/CIMIS/UCDavis_IPM.Daily'\n",
      "dir_cv_cimis = '/Users/karllapo/gdrive/GroundObs/CA_CentralValley.UCDavis/RAW/CIMIS/CIMIS.Hourly'\n",
      "dir_sio_cdwr = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/data/GroundObs/YOS.SIO.Obs'\n",
      "# dir_cv_pestcast = '/Users/karllapo/gdrive/GroundObs/CA_CentralValley.UCDavis/RAW/PestCast'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################\n",
      "## Central Valley Ground Obs - CIMIS, UC IPM ##\n",
      "###############################################\n",
      "if flag_xray_proc == 1:\n",
      "    # Load previously formatted data (in xray format)\n",
      "    os.chdir(dir_data_out)\n",
      "    with xray.open_dataset('cimis_ucipm.obs.daily.xray.nc') as cimis_ucipm_daily:\n",
      "        print(cimis_ucipm_daily.keys())\n",
      "    \n",
      "elif flag_xray_proc == 0:\n",
      "    ###########################\n",
      "    ##### READ CIMIS DATA #####\n",
      "    ###########################\n",
      "    # Read supporting station information\n",
      "    os.chdir(dir_data_out)\n",
      "    stdat = pd.read_csv('All_StationSummary.v2.csv',sep= ',', \\\n",
      "                    index_col=0,na_values=[-9999,'NaN']) # Read the supporting information\n",
      "    stdat = stdat.groupby('Network').get_group('CIMIS')\n",
      "    \n",
      "    # Files to read\n",
      "    os.chdir(dir_cv_cimis_ucipm)\n",
      "    content = os.listdir(os.getcwd())\n",
      "    num_files = len([name for name in os.listdir('.') if os.path.isfile(name)])\n",
      "    \n",
      "    # Empty lists and dictionary literals\n",
      "    stations = []\n",
      "    lat = []\n",
      "    lon = []\n",
      "    elev = []\n",
      "    grobs_cv = {}\n",
      "\n",
      "    # time zone variables\n",
      "    tz_pst = pytz.timezone('US/Pacific')\n",
      "    \n",
      "    for files in content:\n",
      "        # Only read .txt files\n",
      "        if files[-4:] == '.txt':\n",
      "            with open(files, 'r') as datafile:\n",
      "                # Skip the header of arbitrary size and read the column names\n",
      "                line = datafile.readline()\n",
      "                while not line.startswith('\"Station\"'):\n",
      "                    line = datafile.readline()\n",
      "                \n",
      "                ## format the header line for passing to 'read_csv'\n",
      "                line = line.replace('\\n','')\n",
      "                line = line.replace('\"', '')\n",
      "                col_names = line.split(',')\n",
      "                data = pd.read_csv(datafile, names=col_names, sep= ',', parse_dates={'Datetime' : [1,2]},\\\n",
      "                                   index_col='Datetime',skipinitialspace=True,converters={'Time': lambda x: str('2359')})\n",
      "                data.index = data.index.tz_localize(pytz.timezone('US/Pacific'))\n",
      "                \n",
      "                ## Read SW data, asign to PST, and get SW that passes QC\n",
      "                sitename = data['Station'][0][0:-2]\n",
      "                grobs_cv[sitename] = data['Solar']\n",
      "                grobs_cv[sitename].index = data.index\n",
      "    \n",
      "                ## Fill in elevation/lat/lon\n",
      "                if sitename in stdat.index:\n",
      "                    elev.append(stdat.loc[sitename]['elevation (m)'])\n",
      "                    lat.append(stdat.loc[sitename]['lat'])\n",
      "                    lon.append(stdat.loc[sitename]['lon'])\n",
      "                    stations.append(sitename)\n",
      "                else:\n",
      "                    print((\"Site: \"+sitename+\" is missing from master list\"))\n",
      "                    \n",
      "    #########################\n",
      "    ##### READ SIO DATA #####\n",
      "    #########################\n",
      "    os.chdir(dir_sio_cdwr)\n",
      "    content = os.listdir(os.getcwd())\n",
      "    num_files = len([name for name in os.listdir('.') if os.path.isfile(name)])\n",
      "    # Concatenate \n",
      "    cimis_ucipm_daily = pd.concat(grobs_cv,axis=0,keys=stations)\n",
      "    cimis_ucipm_daily = pd.DataFrame(cimis_ucipm_daily)\n",
      "\n",
      "    # Convert to xray\n",
      "    ds = xray.Dataset.from_dataframe(cimis_ucipm_daily)\n",
      "    ds = ds.rename({'level_0':'station','Solar':'SWdwn'})\n",
      "    \n",
      "    # Fill in lat/lon\n",
      "    ds['lat'] = ('station',lat)\n",
      "    ds['lon'] = ('station',lon)\n",
      "    ds['elev'] = ('station',elev)\n",
      "        \n",
      "    ## Output to netcdf\n",
      "    os.chdir(dir_data_out)\n",
      "    ds.to_netcdf('cimis_ucipm.obs.daily.xray.nc')\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'lon', u'Datetime', u'station', u'elev', u'lat', u'SWdwn']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################\n",
      "## Ground Obs - SIO stations ##\n",
      "###############################\n",
      "## Try to use xray to build a netcdf file\n",
      "if flag_sio_cdwr_xray == 1:\n",
      "    # Load previously formatted data (in xray format)\n",
      "    os.chdir(dir_data_out)\n",
      "    with xray.open_dataset('sio_cdwr.obs.xray.nc') as sio_cdwr_daily:\n",
      "        print(sio_cdwr_daily.keys())\n",
      "    \n",
      "elif flag_sio_cdwr_xray == 0:\n",
      "    os.chdir(dir_sio_cdwr)\n",
      "    content = os.listdir(os.getcwd())\n",
      "    num_files = len([name for name in os.listdir('.') if os.path.isfile(name)])\n",
      "    \n",
      "    # Empty lists and dictionary literals\n",
      "    stations = []\n",
      "    lat = []\n",
      "    lon = []\n",
      "    elev = []\n",
      "    grobs_yos = {}\n",
      "    grobs_yos_daily = {}\n",
      "    grobs_yos_daily_proc = {}\n",
      "    \n",
      "    # Read supporting station information\n",
      "    os.chdir(dir_data_out)\n",
      "    stdat = pd.read_csv('All_StationSummary.v2.csv',sep= ',', \\\n",
      "                    index_col=0,na_values=[-9999,'NaN']) # Read the supporting information\n",
      "    stdat = stdat.groupby('Network').get_group('CDWR')\n",
      "    \n",
      "    # time zone variables\n",
      "    tz_pst = pytz.timezone('US/Pacific')\n",
      "        \n",
      "    for files in content:\n",
      "        # Only read QC formatted files\n",
      "        if files[-10:] == 'Rad.QC.txt':\n",
      "            sitename = files.split('.')[0]\n",
      "            stations.append(sitename)\n",
      "            na_value = ['   NaN']\n",
      "            \n",
      "            # Read SW data, convert from UTC to PST, and get SW that passes QC\n",
      "            grobs_yos[sitename] = pd.read_csv(files,sep= '\\t', parse_dates=True, index_col=0, na_values=na_value)\n",
      "            grobs_yos[sitename].index = grobs_yos[sitename].index.tz_localize(pytz.utc).tz_convert(tz_pst)\n",
      "            grobs_yos[sitename]['SWdwn_QC'] = grobs_yos[sitename]['SWdwn_Wm^-2'].where(grobs_yos[sitename]['QCFlag'] == 0)\n",
      "    \n",
      "            # New data frame w/ daily means\n",
      "            grobs_yos_daily[sitename] = grobs_yos[sitename]['SWdwn_Wm^-2'].resample('D', how='mean').to_frame(name='SWdwn_D')\n",
      "            grobs_yos_daily[sitename]['SWdwn_D_QC'] = grobs_yos[sitename]['SWdwn_QC'].resample('D', how='mean')\n",
      "            grobs_yos_daily[sitename]['SWdwn_D_proc'] = grobs_yos[sitename]['SWdwn_proc'].resample('D', how='mean')\n",
      "            \n",
      "            # DataFrame with processed only\n",
      "            grobs_yos_daily_proc[sitename] = pd.DataFrame(grobs_yos_daily[sitename]['SWdwn_D_proc'])\n",
      "            \n",
      "            # Fill in elevation/lat/lon\n",
      "            elev.append(stdat.loc[sitename]['elevation (m)'])\n",
      "            lat.append(stdat.loc[sitename]['lat'])\n",
      "            lon.append(stdat.loc[sitename]['lon'])\n",
      "            \n",
      "    # Concatenate \n",
      "    sio_cdwr_daily = pd.concat(grobs_yos_daily_proc,axis=0,keys=stations)\n",
      "    \n",
      "    # Convert to xray\n",
      "    ds = xray.Dataset.from_dataframe(sio_cdwr_daily)\n",
      "    ds = ds.rename({'level_0':'station'})\n",
      "    ds = ds.rename({'SWdwn_D_proc':'SWdwn'})\n",
      "    \n",
      "    # Fill in lat/lon\n",
      "    ds['lat'] = ('station',lat)\n",
      "    ds['lon'] = ('station',lon)\n",
      "    ds['elev'] = ('station',elev)\n",
      "    \n",
      "    ## Sample usage\n",
      "    # ds.sel(station='bee').to_dataframe()['elev'].values[0]\n",
      "    \n",
      "    ## Output to netcdf\n",
      "    os.chdir(dir_data_out)\n",
      "    ds.to_netcdf('sio_cdwr.obs.xray.nc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    }
   ],
   "metadata": {}
  }
 ]
}