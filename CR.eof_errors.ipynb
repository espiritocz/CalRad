{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################################################\n",
      "# CR.GrobsCompare.ipynb\n",
      "# Karl Lapo July/2015\n",
      "####################################################################################################\n",
      "# Plots comparisons between ground observations and radiation products\n",
      "####################################################################################################\n",
      "\n",
      "# must insert this statement to render the plots within the notebook\n",
      "# this is specific to the ipython notebook\n",
      "%matplotlib inline\n",
      "\n",
      "## FLAGS for processing\n",
      "flag_getdata = 0              # Load and process raw data (1)? Or load pre-processed data (0)?\n",
      "    \n",
      "## Import statements\n",
      "# netcdf/numpy/xray\n",
      "import numpy as np\n",
      "from datetime import datetime, timedelta\n",
      "import pandas as pd\n",
      "import xray\n",
      "\n",
      "# OS interaction\n",
      "import sys, pickle, os\n",
      "\n",
      "# import subplots function for plotting\n",
      "import seaborn as sns\n",
      "import matplotlib\n",
      "from matplotlib.pyplot import subplots\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import cm\n",
      "from mpl_toolkits.basemap import Basemap\n",
      "\n",
      "## Directory listing\n",
      "dir_data = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/data'\n",
      "dir_print = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/Graphics'\n",
      "\n",
      "# List of sub-directory names for each data set\n",
      "dir_NLDAS = '/NLDAS'\n",
      "dir_SYN = '/CERES_SYN'\n",
      "dir_grobs = '/GroundObs'\n",
      "dir_VIC = '/VIC_MTCLIM'\n",
      "dir_MODIS = '/MODIS.IRRAD'\n",
      "\n",
      "# Directory for basemap pickle files\n",
      "dir_bmap = '/Users/karllapo/gdrive/SnowHydrology/proj/CloudClimatology/data/basemap'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################################################\n",
      "# Functions\n",
      "####################################################################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### Basemap\n",
      "def build_basemap(lon,lat,dir_bmap,bmap_name='basemap.pickle',rewrite=False):\n",
      "    # Lat/Lon handling - map extent\n",
      "    bmap_dict = {}\n",
      "    bmap_dict['lat_i'] = np.min(lat)\n",
      "    bmap_dict['lon_i'] = np.min(lon)\n",
      "    bmap_dict['lat_j'] = np.max(lat)\n",
      "    bmap_dict['lon_j'] = np.max(lon)\n",
      "    \n",
      "    bmap_dict['lat_mid'] = lat[np.round(lat.size/2)]\n",
      "    bmap_dict['lon_mid'] = lon[np.round(lon.size/2)]\n",
      "    \n",
      "    bmap_dict['lat_labels'] = np.arange(np.round(bmap_dict['lat_i']), np.round(bmap_dict['lat_j']), 2)\n",
      "    bmap_dict['lon_labels'] = np.arange(np.round(bmap_dict['lon_i']), np.round(bmap_dict['lon_j']), 2)\n",
      "    \n",
      "    os.chdir(dir_bmap)\n",
      "    # Force rewriting basemap pickle file\n",
      "    if rewrite:\n",
      "        bmap = Basemap(llcrnrlon=bmap_dict['lon_i'],llcrnrlat=bmap_dict['lat_i'],\\\n",
      "                        urcrnrlon=bmap_dict['lon_j'],urcrnrlat=bmap_dict['lat_j'],\\\n",
      "                        rsphere=(6378137.00,6356752.3142),resolution='l',area_thresh=1000.,projection='lcc',\\\n",
      "                        lat_1=bmap_dict['lat_mid'],lon_0=bmap_dict['lon_mid'])\n",
      "        pickle.dump(bmap,open(bmap_name,'wb'),-1)\n",
      "    \n",
      "    else:\n",
      "        try:\n",
      "            bmap = pickle.load(open(bmap_name,'rb'))\n",
      "        except IOError as e:\n",
      "            bmap = Basemap(llcrnrlon=bmap_dict['lon_i'],llcrnrlat=bmap_dict['lat_i'],\\\n",
      "                            urcrnrlon=bmap_dict['lon_j'],urcrnrlat=bmap_dict['lat_j'],\\\n",
      "                            rsphere=(6378137.00,6356752.3142),resolution='l',area_thresh=1000.,projection='lcc',\\\n",
      "                            lat_1=bmap_dict['lat_mid'],lon_0=bmap_dict['lon_mid'])\n",
      "            pickle.dump(bmap,open(bmap_name,'wb'),-1)\n",
      "    \n",
      "    return bmap,bmap_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################################################\n",
      "# Functions\n",
      "####################################################################################################\n",
      "\n",
      "##### Iterative eof \n",
      "def naneof_BR2003(X):\n",
      "    if np.nanmean(X) > .001:\n",
      "        # Remove nanmean of data\n",
      "        dat_mean = np.nanmean(X)\n",
      "        X[~np.isnan(X)] = X[~np.isnan(X)]-dat_mean\n",
      "    else:\n",
      "        dat_mean = 0\n",
      "    ## Subset of data for validation, remove nans\n",
      "    X0 = np.copy(X)\n",
      "    idok_r,idok_c = np.nonzero(~np.isnan(X)) \n",
      "    id_val_r = idok_r[np.ceil(np.random.uniform(size=(np.floor(idok_r.shape[0]/50)))* \\\n",
      "                              idok_r.shape[0]).astype(int)] # validation subset (rows)\n",
      "    id_val_c = idok_c[np.ceil(np.random.uniform(size=(np.floor(idok_c.shape[0]/50)))* \\\n",
      "                              idok_c.shape[0]).astype(int)] # validation subset (columns)\n",
      "    \n",
      "    X_val = X[id_val_r,id_val_c]\n",
      "    mx_val = np.nansum(np.nansum(X_val**2))\n",
      "    \n",
      "    # remove validation subset from the data\n",
      "    X[id_val_r,id_val_c] = np.nan;\n",
      "    # Update index of non-nans\n",
      "    idok_r,idok_c = np.nonzero(~np.isnan(X))\n",
      "    # replace NaNs by zeros\n",
      "    X[np.isnan(X)] = 0\n",
      "    \n",
      "    ## find out how many eigenfunctions to retain...\n",
      "    Nit = 100\n",
      "    tol = 1e-8\n",
      "    err = np.empty(min(X.shape[1],20))*np.nan\n",
      "    for Ne in np.arange(1,min(X.shape[1],20)):\n",
      "        X1 = np.copy(X)\n",
      "        for k in np.arange(2,Nit):\n",
      "            # compute SVD (equivalent of economy method in matlab)\n",
      "            U,D,V = np.linalg.svd(X1,full_matrices=False)\n",
      "    \n",
      "            # truncate and estimate \"interpolated\" D\n",
      "            N = Ne\n",
      "            Ut = U[:,0:N]\n",
      "            Dt = D[0:N]\n",
      "            Vt = V[0:N,:]\n",
      "            Xa = np.dot(np.dot(Ut,np.diag(Dt)),Vt)\n",
      "            Xa[idok_r,idok_c] = X[idok_r,idok_c] # restore real data\n",
      "            X2 = np.copy(Xa)\n",
      "    \n",
      "            # termination criterium?\n",
      "            dx=np.nansum((X2-X1)**2,axis=1)\n",
      "            dx=dx[:,np.newaxis]\n",
      "            mx=np.nansum(X2**2,axis=1)\n",
      "            mx=mx[:,np.newaxis]\n",
      "            dxex = np.linalg.lstsq(dx.T,mx.T)\n",
      "            dxex = dxex[-1]\n",
      "            if dxex < tol:\n",
      "                print('Converged in '+str(k-1)+' iterations to the tolerance of '+str(tol))\n",
      "                break\n",
      "            X1 = np.copy(X2)\n",
      "    \n",
      "        # error?\n",
      "        Xa = np.dot(np.dot(Ut,np.diag(Dt)),Vt)\n",
      "        dx_val = np.nansum(np.nansum((Xa[id_val_r,id_val_c]-X_val)**2))\n",
      "        err[Ne] = dx_val/mx_val\n",
      "    \n",
      "    ## Loop through again using the optimal number of eigenvalues only\n",
      "    Nopt = np.flatnonzero(err == np.nanmin(err))\n",
      "    \n",
      "    X1 = np.copy(X0);\n",
      "    # Subset of data for validation\n",
      "    idok_r,idok_c = np.nonzero(~np.isnan(X1)) \n",
      "    X1[np.isnan(X1)] = 0\n",
      "    for k in np.arange(2,Nit):\n",
      "        # compute SVD (equivalent of economy method in matlab)\n",
      "        U,D,V = np.linalg.svd(X1,full_matrices=False)#     N = Nopt;\n",
      "        # truncate and estimate \"interpolated\" D\n",
      "        N = Nopt\n",
      "        Ut = U[:,0:N]\n",
      "        Dt = D[0:N]\n",
      "        Vt = V[0:N,:]\n",
      "        Xa = np.dot(np.dot(Ut,np.diag(Dt)),Vt)\n",
      "        Xa[idok_r,idok_c] = X[idok_r,idok_c] # restore real data\n",
      "        X2 = np.copy(Xa)\n",
      "        \n",
      "        # termination criterium?\n",
      "        dx=np.nansum((X2-X1)**2,axis=1)\n",
      "        dx=dx[:,np.newaxis]\n",
      "        mx=np.nansum(X2**2,axis=1)\n",
      "        mx=mx[:,np.newaxis]\n",
      "        dxex = np.linalg.lstsq(dx.T,mx.T)\n",
      "        dxex = dxex[-1]\n",
      "        if dxex < tol:\n",
      "            print('Converged in '+str(k-1)+' iterations to the tolerance of '+str(tol))\n",
      "            break\n",
      "        X1 = np.copy(X2)\n",
      "        \n",
      "    # units in B\n",
      "    B = np.dot(U,D)  #the temporal modes\n",
      "    amps = V # the spatial modes\n",
      "    #the variance of the original temperature series\n",
      "    orig_var = np.nanmean(X0**2) \n",
      "    #divide by the product of the original matrix size and by the variance\n",
      "    variance = D**2/orig_var*100/(X0.shape[0]*X0.shape[1])\n",
      "    \n",
      "    return(B,amps,variance,dat_mean,Nopt,U,V,D)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################\n",
      "## Read previously processed data ##\n",
      "####################################\n",
      "# ///// See CC.CA.StatisticsMaps.Master for details on creation of xray data \n",
      "\n",
      "###########\n",
      "## NLDAS ##\n",
      "os.chdir(dir_data+dir_NLDAS)\n",
      "nldas = xray.open_dataset('CA.NLDAS.irrad.monthly.nc')\n",
      "nldas = nldas.rename({'DLWRF_110_SFC':'LWdwn','DSWRF_110_SFC':'SWdwn'})\n",
      "\n",
      "#########\n",
      "## SYN ##\n",
      "os.chdir(dir_data+dir_SYN)\n",
      "syn = xray.open_dataset('CA.syn.irrad.monthly.nc')\n",
      "syn.longitude.values = syn.longitude.values-360\n",
      "syn.latitude.values = syn.latitude.values[::-1]\n",
      "# Flip the syn array spatially\n",
      "for d in np.arange(syn.time.size):\n",
      "    syn.SWdwn.values[d-1,:,:] = np.flipud(syn.SWdwn.values[d-1,:,:])\n",
      "    syn.LWdwn.values[d-1,:,:] = np.flipud(syn.LWdwn.values[d-1,:,:])\n",
      "\n",
      "############\n",
      "## MTCLIM ##\n",
      "os.chdir(dir_data+dir_VIC)\n",
      "mtclim = xray.open_dataset('CA.MTCLIM.irrad.monthly.nc')\n",
      "\n",
      "#########################\n",
      "## Ground Observations ##\n",
      "os.chdir(dir_data+dir_grobs)\n",
      "grobs = xray.open_dataset('CA.grobs.irrad.monthly.nc')\n",
      "grobs.SWdwn.values[grobs.SWdwn.values == 0] = np.nan\n",
      "grobs = grobs.rename({'lon':'longitude','lat':'latitude'})\n",
      "grobs.longitude.values = -grobs.longitude.values\n",
      "\n",
      "###########\n",
      "## MODIS ##\n",
      "os.chdir(dir_data+dir_MODIS)\n",
      "modis = xray.open_dataset('CA.MODIS.irrad.monthly.nc')\n",
      "modis.SWdwn.values[modis.SWdwn.values == 0] = np.nan\n",
      "modis = modis.rename({'lon':'longitude','lat':'latitude'})\n",
      "\n",
      "## List w/ all irradiance datasets\n",
      "monthly_mean = {}\n",
      "monthly_mean['syn'] = syn\n",
      "monthly_mean['nldas'] = nldas\n",
      "monthly_mean['mtclim'] = mtclim\n",
      "monthly_mean['modis'] = modis\n",
      "monthly_mean['grobs'] = grobs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################\n",
      "## Find grid point containing each ground station ##\n",
      "####################################################\n",
      "pr_names = ['mtclim','syn','nldas','modis']\n",
      "\n",
      "# Station lat and lon\n",
      "lon_stat = grobs.longitude.values\n",
      "lat_stat = grobs.latitude.values\n",
      "\n",
      "for pr in pr_names:        \n",
      "\n",
      "    # lat/lon for product\n",
      "    lon_rad = monthly_mean[pr].longitude.values\n",
      "    lat_rad = monthly_mean[pr].latitude.values  \n",
      "    # mesh\n",
      "    lonm, latm = np.meshgrid(lon_rad,lat_rad)\n",
      "    \n",
      "    # Empty numpy array\n",
      "    to_merge = np.empty((monthly_mean[pr].time.size,grobs.station.size))\n",
      "    \n",
      "    ## Product values in each grid containing station\n",
      "    for stat in grobs.station.values:\n",
      "        \n",
      "        # Station index\n",
      "        stat_ind = np.where(stat == grobs.station.values)\n",
      "        # Distance to product grid lat-lon\n",
      "        d = (latm-lat_stat[stat_ind])**2 + (lonm-lon_stat[stat_ind])**2\n",
      "        # Index of closest product grid\n",
      "        dind = np.where(d==np.amin(d))\n",
      "        # Grad grid values at the station, put into xray dataset\n",
      "        to_merge[:,stat_ind[0]] = monthly_mean[pr].SWdwn.values[:,dind[0][0],dind[1][0],np.newaxis]\n",
      "    \n",
      "    ## Merge products w/ grobs xray structure\n",
      "    to_merge_ds = xray.Dataset({pr:(('time','station'),to_merge), \\\n",
      "                                    'time':monthly_mean[pr].time.values,\\\n",
      "                                    'station':grobs.station.values})\n",
      "    grobs = grobs.merge(to_merge_ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######## EOF of errors for each station\n",
      "pr_names = ['mtclim','syn','nldas']\n",
      "# Build basemap\n",
      "lat = monthly_mean['mtclim'].latitude.values\n",
      "lon = monthly_mean['mtclim'].longitude.values\n",
      "\n",
      "bmp,bmd = build_basemap(lon,lat,dir_bmap,'CA.Domain.bmp.pickle',rewrite=True)\n",
      "lat_labels = bmd['lat_labels']\n",
      "lon_labels = bmd['lon_labels']\n",
      "\n",
      "# Station lat and lon\n",
      "lon_stat = grobs.longitude.values\n",
      "lat_stat = grobs.latitude.values\n",
      "\n",
      "for pr in pr_names:\n",
      "    print(pr)\n",
      "    B,amps,variance,dat_mean,Nopt,U,V,D = naneof_BR2003(grobs[pr].values-grobs.SWdwn.values)\n",
      "    \n",
      "    ## Plot Results\n",
      "    fig = plt.figure(figsize=(15,5))\n",
      "    gs = matplotlib.gridspec.GridSpec(1,4)\n",
      "    ax = plt.subplot(gs[0])\n",
      "    ax.plot(np.arange(1,11),variance[0:10])\n",
      "    ax.set_title('eof variance explained')\n",
      "    ax.set_ylabel('variance')\n",
      "    ax.set_xlabel('eof #')\n",
      "    for n in np.arange(0,3):\n",
      "        ax = plt.subplot(gs[n+1])\n",
      "        im = bmp.scatter(lon_stat,lat_stat,c=amps[n,:],s=75, linewidths=.25,latlon=True)\n",
      "        ax.set_title('eof coef '+str(n+1))\n",
      "    \n",
      "        ## Format\n",
      "        if n == 0:\n",
      "            bmp.drawparallels(lat_labels,labels=[1,0,0,0])\n",
      "        else:\n",
      "            bmp.drawparallels(lat_labels)\n",
      "        bmp.drawmeridians(lon_labels,labels=[0,0,0,1]) \n",
      "    \n",
      "        # political boundaries.\n",
      "        bmp.drawstates()\n",
      "        bmp.drawcoastlines()\n",
      "        bmp.drawcounties()\n",
      "\n",
      "    fig.tight_layout()\n",
      "    \n",
      "    os.chdir(dir_print)\n",
      "    fname = 'eof_errors.'+pr+'.png'\n",
      "    fig.savefig(fname)\n",
      "    plt.close(fig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mtclim\n",
        "Converged in 9 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 2 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "syn"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 8 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 9 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 10 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 11 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 12 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 13 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 14 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 16 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 17 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 26 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 24 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 27 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 33 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 37 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 48 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 45 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 2 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nldas"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 9 iterations to the tolerance of 1e-08\n",
        "Converged in 11 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 12 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 12 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 20 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 20 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 25 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 25 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 32 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 50 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 38 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 39 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 43 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 76 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 79 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 78 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 98 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged in 2 iterations to the tolerance of 1e-08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    }
   ],
   "metadata": {}
  }
 ]
}